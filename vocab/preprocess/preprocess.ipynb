{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cambridge_dictionary():\n",
    "    data = None\n",
    "    with open(\"../data/cambridge/cambridge.word.json\") as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mw_xml_to_dict(soup, start_word, num_word, stop_word):\n",
    "  \"\"\"\n",
    "  Get example sentences from the webster dictionary\n",
    "  input:\n",
    "    soup: BeautifulSoup object\n",
    "    start_word: the word we want to start with\n",
    "    num_word: number of words we want to get\n",
    "    stop_word: the word we want to stop at\n",
    "  output:\n",
    "    output_dict: a dictionary contains the word and its example sentences\n",
    "  \"\"\"\n",
    "  pattern = r\"{ldquo}|{rdquo}|{it}|{phrase}|{/phrase}|{dx}|{/dx}|\\[\\=.*\\]|\\n\"\n",
    "  output_dict = {}\n",
    "  word_count = 0\n",
    "  find = False\n",
    "  # Find all words that contain example sentence/phrase\n",
    "  for word in soup.find_all('entry'):\n",
    "    # Get the number of words we want\n",
    "    if (stop_word != None and word.find('id').text == stop_word):\n",
    "      break\n",
    "    elif (find and word_count == num_word):\n",
    "      break\n",
    "\n",
    "    # First, find the target word\n",
    "    word_id = word.find('id').text\n",
    "    if (not find) and (word_id != start_word):\n",
    "      continue\n",
    "    else:\n",
    "      find = True\n",
    "\n",
    "    # Find each definition of POS of the word\n",
    "    pos = word.find_all('fl')\n",
    "    big_sense_list = []\n",
    "    output_dict[word_id] = {}\n",
    "    for ele in pos:\n",
    "      fl = ele.contents[0]\n",
    "      output_dict[word_id][fl] = []\n",
    "      pos_list = []\n",
    "\n",
    "      definition = ele.find_next('def')  # big sense\n",
    "      big_sense_list = []\n",
    "      # Find senses for each definition\n",
    "      senses = definition.find_all('sense')\n",
    "\n",
    "\n",
    "      for content in senses:\n",
    "        sense_dict = {}\n",
    "        sense = content.find('dt')\n",
    "        if sense.contents[0] == '\\n':\n",
    "          sense = sense.find('un').contents[0]\n",
    "          sense = re.sub(pattern, \"\", sense)\n",
    "        else:\n",
    "          sense = sense.contents[0]\n",
    "          sense = re.sub(pattern, \"\", sense)\n",
    "        sense_dict[\"en_def\"] = sense\n",
    "\n",
    "\n",
    "        # Get example sentences\n",
    "        examples = content.find_all('vi')\n",
    "        exam_list = []\n",
    "        if examples != []:\n",
    "          for sentence in examples:\n",
    "            example = re.sub(pattern, \"\", sentence.text)\n",
    "            example = example.replace(r\"{/it}\", \"\")\n",
    "            exam_dict = {\"en\": example}\n",
    "            exam_list.append(exam_dict)\n",
    "        sense_dict[\"examples\"] = exam_list\n",
    "\n",
    "        big_sense_list.append({\"sense\": [sense_dict]})\n",
    "      output_dict[word_id][fl].append({\"big_sense\": big_sense_list})\n",
    "\n",
    "    word_count += 1\n",
    "  return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_webster_dictionary(start_word, stop_word=None, num_word=0):\n",
    "    file = None\n",
    "    with open(f\"../data/mw/mw-xml/LD_u.xml\", \"r\") as f:\n",
    "      file = f.read()\n",
    "    soup = BeautifulSoup(file, 'xml')\n",
    "    output_dict = convert_mw_xml_to_dict(soup, start_word, num_word, stop_word)\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_dict = load_cambridge_dictionary()\n",
    "web_dict = load_webster_dictionary(\"ugly\", \"understand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = cam_dict.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../data/mw/mw-json/mw.word.json\", \"w\") as f:\n",
    "#     json.dump(web_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtain target word and its senses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_and_sense(word, dictionary, word_sense):\n",
    "    \"\"\"\n",
    "    Get the word and its sense from the dictionary\n",
    "    input:\n",
    "      word: the word we want to find\n",
    "      dictionary: the dictionary that contains the word\n",
    "      word_sense: a dictionary contains the word and its sense\n",
    "    output:\n",
    "      word_sense: a dictionary contains the word and its sense\n",
    "    \"\"\"\n",
    "    senses = []\n",
    "    for pos in dictionary[word]:\n",
    "        for big_sense_list in dictionary[word][pos]:\n",
    "            for big_sense in big_sense_list[\"big_sense\"]:\n",
    "                for sense in big_sense[\"sense\"]:\n",
    "                    senses.append(sense[\"en_def\"])\n",
    "    word_sense[word] = senses\n",
    "\n",
    "    return word_sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ugly': ['unpleasant to look at; not attractive', 'unpleasant and threatening or violent']} {'ugly': ['{bc}unpleasant to look at {bc}not pretty or attractive ', '{bc}unpleasant to hear ', '{bc}offensive or disgusting ', '{bc}very bad or unpleasant ', 'see {dxt|head:1||}']}\n"
     ]
    }
   ],
   "source": [
    "word_sense_cam = {}\n",
    "word_sense_web = {}\n",
    "word_sense_cam = get_word_and_sense(\"ugly\", cam_dict, word_sense_cam)\n",
    "word_sense_web = get_word_and_sense(\"ugly\", web_dict, word_sense_web)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ugly': ['unpleasant to look at; not attractive',\n",
       "  'unpleasant and threatening or violent']}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_sense_cam"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_lg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
